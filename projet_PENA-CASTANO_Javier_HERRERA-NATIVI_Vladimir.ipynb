{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEÑA CASTAÑO Javier, HERRERA NATIVI Vladimir\n",
    "\n",
    "# Projet détection de symptomes radiologiques sur des X-rays \n",
    " \n",
    "\n",
    "## Structure du Rapport Notebook\n",
    "\n",
    "Notre rapport sera présenté sous forme de notebook Jupyter ayant au fur et a mesure des explications grace a des markdownds, cette impkémentation nous permettra un projet plus interatifc et guidée. \n",
    "1. **Eplications** (cellules Markdown)  \n",
    "   - Explications des méthodes  \n",
    "   - Justifications des choix  \n",
    "   - Analyse interprétative des résultats  \n",
    "\n",
    "2. **Preuves exécutables** (cellules de code)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Contexte et Motivation  \n",
    "Dans le domaine de la santé, l'intelligence artificielle ouvre des perspectives prometteuses pour l'aide au diagnostic, notamment dans l'analyse d'imagerie médicale. Ce projet s'inscrit dans cette idée, voulant exploiter le dataset NIH Chest X-ray 14 ([disponible sur Kaggle](https://www.kaggle.com/datasets/nih-chest-xrays/data)), contenant **112 120 radiographies thoraciques** annotées avec des informations cliniques et démographiques.  \n",
    "\n",
    "Notre objectif ? \n",
    "- Eliminer les possibles biais par rapport a deux attributs protégés, \"Patient Gender\" et \"Age\" \n",
    "- Etudier les métriques associés au différents modèles\n",
    "\n",
    "## Méthodologie Globale  \n",
    "Le projet s'articule en deux phases complémentaires :  \n",
    "\n",
    "1. **Pre-processing** :  \n",
    "   - Rééchantillonnage/Réponderation équitable (Reweighting, DIR, Uniform Sampling)  \n",
    " \n",
    "\n",
    "2. **Post-processing** :  \n",
    "   - Ajustement des seuils de classification (Reject Option)  \n",
    "   - Calibration des probabilités (Equalized Odds)  \n",
    "\n",
    "L'évaluation s'appuie systématiquement sur la librairie AIF360."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Datasets\n",
    "import os \n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.sklearn.metrics import *\n",
    "\n",
    "\n",
    "#graphiques\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# Modèles d'entrainement \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from aif360.algorithms.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"HERRERA_NATIVI_VLADIMIR\"\n",
    "metadata_Vlad = pd.read_csv(\"HERRERA_NATIVI_VLADIMIR/metadata.csv\")\n",
    "metadata_Javi = pd.read_csv(\"PENA_CASTANO_JAVIER/metadata.csv\")\n",
    "# La prof ma parlé d'un tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vladi : (5627, 13) | Javi : (5477, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vladi : {metadata_Vlad.shape} | Javi : {metadata_Javi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des données utilisées:\n",
    "\n",
    "On a choisi les données de vladimir simplement car il y a plus d'entrées, puis on a éliminé colonnes inutiles pour notre études et les lignes impossibles, incohérentes ou avec des valeurs incomplètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>WEIGHTS</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000006_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000025_000.png</td>\n",
       "      <td>Effusion</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000029_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000072_000.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000090_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>67</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>00030752_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30752</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>00030772_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30772</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>00030772_001.png</td>\n",
       "      <td>Consolidation</td>\n",
       "      <td>1</td>\n",
       "      <td>30772</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>00030772_002.png</td>\n",
       "      <td>Consolidation</td>\n",
       "      <td>2</td>\n",
       "      <td>30772</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>00030805_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30805</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5626 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
       "0     00000006_000.png     No Finding            0           6           81   \n",
       "1     00000025_000.png       Effusion            0          25           71   \n",
       "2     00000029_000.png     No Finding            0          29           59   \n",
       "3     00000072_000.png    Atelectasis            0          72           67   \n",
       "4     00000090_000.png     No Finding            0          90           67   \n",
       "...                ...            ...          ...         ...          ...   \n",
       "5622  00030752_000.png     No Finding            0       30752           64   \n",
       "5623  00030772_000.png     No Finding            0       30772           26   \n",
       "5624  00030772_001.png  Consolidation            1       30772           26   \n",
       "5625  00030772_002.png  Consolidation            2       30772           26   \n",
       "5626  00030805_000.png     No Finding            0       30805           27   \n",
       "\n",
       "     Patient Gender View Position  WEIGHTS  train  \n",
       "0                 M            PA        1   True  \n",
       "1                 M            PA        1   True  \n",
       "2                 F            PA        1  False  \n",
       "3                 F            PA        1   True  \n",
       "4                 F            PA        1   True  \n",
       "...             ...           ...      ...    ...  \n",
       "5622              F            AP        1   True  \n",
       "5623              F            AP        1   True  \n",
       "5624              F            AP        1   True  \n",
       "5625              F            AP        1   True  \n",
       "5626              M            PA        1   True  \n",
       "\n",
       "[5626 rows x 9 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimination des colonnes non necessaire pour notre étude initial\n",
    "colonnes_a_eliminer = ['OriginalImage[Width','Height]', 'OriginalImagePixelSpacing[x', 'y]']\n",
    "data = metadata_Vlad.drop(columns=colonnes_a_eliminer, inplace=False) \n",
    "data = data.loc[data['Patient Age'] <= 120] # On élimine les patients qui ont plus de 120 ans \n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse quantitative des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graphiques = data.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a crée plusieurs graphiques pour voir la repartition des données en fonction de l'age, le sexe et la position de vue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage de graphiques pour la visualisation de la repartition de l'age, le follow up, le genre et la position\n",
    "fig = make_subplots(rows = 2, cols=2, subplot_titles = [\"Follow Up\", \"Age\", \"Gender\", \"Position\"])\n",
    "fig.add_trace (go.Histogram(x=data_graphiques['Follow-up #'], name= \"follow up\"), row = 1, col=1)\n",
    "fig.add_trace (go.Histogram(x=data_graphiques['Patient Age'], name= \"Age\"), row = 1, col=2)\n",
    "fig.add_trace (go.Histogram(x=data_graphiques['Patient Gender'], name= \"Gender\"), row = 2, col=1)\n",
    "fig.add_trace (go.Histogram(x=data_graphiques['View Position'], name= \"Position\"), row = 2, col=2)\n",
    "\n",
    "fig.update_layout(title = \"Histograms\")\n",
    "fig.write_image(\"Histogrammes1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on fait de même, mais on normalise les données et on sépare les personnes malades et les personnes saines.\n",
    "\n",
    "Normaliser et séparer les données va nous permettre de comparer la proportion de personnes malades et saines en fonction de l'age, du genre et de la position de vue. Ceci nous a permit de répérer les attributs favorisés et les non favorisés: les attributs favorisés sont les femmes, PA et les jeunes (0-40 ans). Comme notre label a analyser est \"Finding Labels\" et notre valeur a favoriser est être sain ( \"No Finding\"), les attributs favorisés serons les attributs qui on la proportion sains/malades la plus haute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121505/965901324.py:14: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Créons d'abord une colonne pour identifier les patients malades et non malades\n",
    "data_graphiques['Est_Malade'] = ~data_graphiques['Finding Labels'].str.contains('No Finding')\n",
    "data_graphiques['status'] = data_graphiques['Est_Malade'].map({True: 'Malade', False: 'Non malade'})\n",
    "\n",
    "# Histogramme pour l'âge\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=[\"Âge\", \"Genre\", \"Position\"])\n",
    "\n",
    "# Groupes d'âge\n",
    "age_bins = [0, 40, 100]  # Définir 4 tranches d'âge\n",
    "age_labels = ['0-40', '41-100+']\n",
    "data_graphiques['age_group'] = pd.cut(data_graphiques['Patient Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Compte normalisé par groupe d'âge et par statut (malade/non malade)\n",
    "age_counts = data_graphiques.groupby(['age_group', 'status']).size().unstack(fill_value=0)\n",
    "age_counts_normalized = age_counts.div(age_counts.sum(axis=0), axis=1)\n",
    "\n",
    "# Ajout du trace pour l'âge\n",
    "for status, color in zip(['Malade', 'Non malade'], ['red', 'green']):\n",
    "    if status in age_counts_normalized.columns:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=age_counts_normalized.index,\n",
    "                y=age_counts_normalized[status],\n",
    "                name=status,\n",
    "                marker_color=color\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "# Histogramme pour le genre\n",
    "gender_counts = data_graphiques.groupby(['Patient Gender', 'status']).size().unstack(fill_value=0)\n",
    "gender_counts_normalized = gender_counts.div(gender_counts.sum(axis=0), axis=1)\n",
    "\n",
    "for status, color in zip(['Malade', 'Non malade'], ['red', 'green']):\n",
    "    if status in gender_counts_normalized.columns:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=gender_counts_normalized.index,\n",
    "                y=gender_counts_normalized[status],\n",
    "                name=status,\n",
    "                marker_color=color,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "# Histogramme pour la position\n",
    "position_counts = data_graphiques.groupby(['View Position', 'status']).size().unstack(fill_value=0)\n",
    "position_counts_normalized = position_counts.div(position_counts.sum(axis=0), axis=1)\n",
    "\n",
    "for status, color in zip(['Malade', 'Non malade'], ['red', 'green']):\n",
    "    if status in position_counts_normalized.columns:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=position_counts_normalized.index,\n",
    "                y=position_counts_normalized[status],\n",
    "                name=status,\n",
    "                marker_color=color,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=3\n",
    "        )\n",
    "\n",
    "# Mise à jour de la mise en page\n",
    "fig.update_layout(\n",
    "    title=\"Distribution normalisée par catégorie (Malades vs Non malades)\",\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    bargap=0.1,\n",
    "    bargroupgap=0.2,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Proportion\", range=[0, 1])\n",
    "fig.update_xaxes(title_text=\"Groupe d'âge\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Genre\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Position\", row=1, col=3)\n",
    "\n",
    "# Sauvegarde de l'image\n",
    "fig.write_image(\"Histogrammes_normalises.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage binaire pour Patient Gender et View Position\n",
    "data['Patient Gender'] = (data['Patient Gender'] == 'F').astype(int) # F est associé a la valeur 1 \n",
    "data['View Position'] = (data['View Position'] == 'AP').astype(int) # AP est associé a la valeur 1  \n",
    "\n",
    "# On effectue un encodage binaire pour finding labels du fait qu'on s'interesse uniquement au fait d'être malade ou pas (on n'essaye pas de prédire les maladies)\n",
    "data['Finding Labels'] = (data['Finding Labels'] == 'No Finding').astype(int) # No Finding est associé a la valeur 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sauvegarder une fois que le pretraitement sera fait \n",
    "data.to_csv(f\"{data_dir}/metadata_encod.csv\", index=False) # sauvegarde de csv encodé "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première methode naïve de pre-processing : reweighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première aproche a la main pour \"Patient Gender\"\n",
    "\n",
    "On commence avec le pre-processing, et on utilise la méthode du cours \"Repondération des données\".\n",
    "\n",
    "Pour bien comprendre l'algorithme utilisé, on choisi de faire à la main le premier calcul de poids pour le genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids calculées pour les sexes :\n",
      "Femme Malade : 1.033302225044209\n",
      "Femme Saine : 0.9734456018962356\n",
      "Homme Malade : 0.9754662395970608\n",
      "Homme Sain : 1.0217508263870834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------  Répondération en fonction du genre  -------------------------------------------\n",
    "nbtotSexe =  (data[\"Patient Gender\"]).count()\n",
    "nbFemmes = (data[\"Patient Gender\"] == 1).sum()\n",
    "nbHommes = (data[\"Patient Gender\"] == 0).sum()\n",
    "nbMalades = (data[\"Finding Labels\"] == 0).sum()\n",
    "nbSains = nbtotSexe - nbMalades\n",
    "\n",
    "# études pour les femmes\n",
    "nbFemmesMalades = ((data[\"Patient Gender\"] == 1) & (data[\"Finding Labels\"] == 0)).sum()\n",
    "nbFemmesSain = nbFemmes - nbFemmesMalades\n",
    "propFMF = nbFemmesMalades / nbFemmes\n",
    "propFM = nbFemmesMalades / nbtotSexe\n",
    "propFS = 1 - propFM\n",
    "propFSF = 1 - propFMF\n",
    "\n",
    "# étude pour les hommes\n",
    "nbHommesMalades = ((data[\"Patient Gender\"] == 0) & (data[\"Finding Labels\"] == 0)).sum()\n",
    "nbHommesSain = nbHommes - nbHommesMalades\n",
    "propHMH = nbHommesMalades / nbHommes  # proportions des Hommes malades sur popHommes \n",
    "propHM = nbHommesMalades / nbtotSexe \n",
    "propHS = 1 - propHM\n",
    "propHSH = 1 - propHMH  # proportions des Hommes sains sur popHommes \n",
    "\n",
    "\n",
    "poidsFM = (nbFemmes * nbMalades) / (nbFemmesMalades * nbtotSexe)\n",
    "poidsFS = (nbFemmes * nbSains) / (nbFemmesSain * nbtotSexe)\n",
    "\n",
    "poidsHM = (nbHommes * nbMalades) / (nbHommesMalades * nbtotSexe)\n",
    "poidsHS = (nbHommes * nbSains) / (nbHommesSain * nbtotSexe)\n",
    "\n",
    "print(f\"Poids calculées pour les sexes :\\nFemme Malade : {poidsFM}\\nFemme Saine : {poidsFS}\\nHomme Malade : {poidsHM}\\nHomme Sain : {poidsHS}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation de l'algorithme automatisé\n",
    "\n",
    "Ensuite, après avoir compris l'algo, on a mit en place une fonction \"re_sampling_naive\", qui prend en argument un dataframe D, un attribut S, et le label (\"Finding Labels\" dans ce cas).\n",
    "\n",
    "Après avoir appliquer l'algorithme à la position de vue et a l'age, les nouveau poids on était calculés et enregistrés dans u tableau. D'autre part, on a affecté les poids a des variables à la main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Favorisés : Jeunes (0-20 ans), Femmes (F), PA\n",
    "\n",
    "# Défavorisés : Adultes (41-80 ans),Hommes(M),AP\n",
    "\n",
    "def groupes_bw(S):\n",
    "    if S == \"Patient Gender\":\n",
    "        return [0, 1]\n",
    "    elif S == \"View Position\":\n",
    "        return [1, 0]\n",
    "    elif S == \"Age Group\":\n",
    "        return [1, 0]\n",
    "\n",
    "\n",
    "def re_sampling_naive(D, S, Label):\n",
    "    W = []\n",
    "    groupes = groupes_bw(S)\n",
    "    for s in groupes:\n",
    "        for c in [0, 1]:  # classes - et +\n",
    "            num = ((D[S] == s).sum())*((D[Label]==c).sum())\n",
    "            denom = (((D[S] == s) & (D[Label] == c)).sum()) * D.shape[0]\n",
    "            poid =   num / denom\n",
    "            W.append(poid)\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8660089311858132),\n",
       " np.float64(1.150692505153632),\n",
       " np.float64(1.1149736044363807),\n",
       " np.float64(0.9197266785927081)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poids_VP = re_sampling_naive(data,\"View Position\", \"Finding Labels\" )\n",
    "\n",
    "poidsAPM = poids_VP[0]\n",
    "poidsAPS = poids_VP[1]\n",
    "\n",
    "poidsPAM = poids_VP[2]\n",
    "poidsPAS = poids_VP[3]\n",
    "poids_VP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vue que les ages ne sont pas binaires, on a crée un attribut de data 'Age Group', qui sépare les jeunes (0 - 39 ans) et les vieux (40 - 120), puis on applique l'algo a cet attribut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9855372894715779),\n",
       " np.float64(1.0125771911382422),\n",
       " np.float64(1.0322783050765911),\n",
       " np.float64(0.9742161286775578)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seuil_age = 40\n",
    "data['Age Group'] = np.where(data['Patient Age'] >= seuil_age, 1, 0) # 1 répresent les \"vieux\"\n",
    "\n",
    "poids_AGE = re_sampling_naive(data,\"Age Group\", \"Finding Labels\" )\n",
    "\n",
    "poidsVieuxM = poids_AGE[0]\n",
    "poidsVieuxS = poids_AGE[1]\n",
    "\n",
    "poidsJeunesM = poids_AGE[2]\n",
    "poidsJeunesS = poids_AGE[3]\n",
    "poids_AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après affecter toutes les poids calculés, on introduit 3 colonnes avec les poids calculés a notre dataframe non encodé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des nouvelles colonnes avec des valeurs par défaut\n",
    "# On supprime les colonnes inutiles et on filtre les patients de plus de 120 ans\n",
    "data_c = metadata_Vlad.drop(columns=colonnes_a_eliminer, inplace=False)  \n",
    "data_c = data_c.loc[data_c['Patient Age'] <= 120]  # Élimine les patients âgés de plus de 120 ans\n",
    "\n",
    "# Création des colonnes de poids avec des valeurs par défaut à 1.0\n",
    "data_c['Age Group'] = np.where(data_c['Patient Age'] >= seuil_age, 1, 0)  # Binarisation de l'âge (1 = vieux, 0 = jeune)\n",
    "data_c['poids_reweigth_gender'] = 1.0  # Poids par défaut pour le genre\n",
    "data_c['poids_reweigth_PA'] = 1.0      # Poids par défaut pour la position (AP/PA)\n",
    "data_c['poids_reweigth_age'] = 1.0      # Poids par défaut pour l'âge\n",
    "\n",
    "# Attribution des poids en fonction du genre et de l'état de santé\n",
    "# Pour les femmes (Genre = \"F\")\n",
    "data_c.loc[(data_c['Patient Gender'] == \"F\") & (data_c['Finding Labels'] != \"No Finding\"), 'poids_reweigth_gender'] = poidsFM  # Femmes malades\n",
    "data_c.loc[(data_c['Patient Gender'] == \"F\") & (data_c['Finding Labels'] == \"No Finding\"), 'poids_reweigth_gender'] = poidsFS    # Femmes saines\n",
    "\n",
    "# Pour les hommes (Genre = \"M\")\n",
    "data_c.loc[(data_c['Patient Gender'] == \"M\") & (data_c['Finding Labels'] != \"No Finding\"), 'poids_reweigth_gender'] = poidsHM  # Hommes malades\n",
    "data_c.loc[(data_c['Patient Gender'] == \"M\") & (data_c['Finding Labels'] == \"No Finding\"), 'poids_reweigth_gender'] = poidsHS    # Hommes sains\n",
    "\n",
    "# Attribution des poids en fonction de la position (AP/PA) et de l'état de santé\n",
    "# Pour la position AP (View Position = \"AP\")\n",
    "data_c.loc[(data_c['View Position'] == \"AP\") & (data_c['Finding Labels'] != \"No Finding\"), 'poids_reweigth_PA'] = poidsAPM  # AP malade\n",
    "data_c.loc[(data_c['View Position'] == \"AP\") & (data_c['Finding Labels'] == \"No Finding\"), 'poids_reweigth_PA'] = poidsAPS    # AP sain\n",
    "\n",
    "# Pour la position PA (View Position = \"PA\")\n",
    "data_c.loc[(data_c['View Position'] == \"PA\") & (data_c['Finding Labels'] != \"No Finding\"), 'poids_reweigth_PA'] = poidsPAM  # PA malade\n",
    "data_c.loc[(data_c['View Position'] == \"PA\") & (data_c['Finding Labels'] == \"No Finding\"), 'poids_reweigth_PA'] = poidsPAS    # PA sain\n",
    "\n",
    "# Attribution des poids en fonction de l'âge et de l'état de santé\n",
    "# Pour les patients âgés (Age Group = 1)\n",
    "data_c.loc[(data_c['Age Group'] == 1) & (data_c['Finding Labels'] != \"No Finding\"), 'poids_reweigth_age'] = poidsVieuxM  # Âgé malade\n",
    "data_c.loc[(data_c['Age Group'] == 1) & (data_c['Finding Labels'] == \"No Finding\"), 'poids_reweigth_age'] = poidsVieuxS    # Âgé sain\n",
    "\n",
    "# Pour les patients jeunes (Age Group = 0)\n",
    "data_c.loc[(data_c['Age Group'] == 0) & (data_c['Finding Labels'] != \"No Finding\"), 'poids_reweigth_age'] = poidsJeunesM  # Jeune malade\n",
    "data_c.loc[(data_c['Age Group'] == 0) & (data_c['Finding Labels'] == \"No Finding\"), 'poids_reweigth_age'] = poidsJeunesS    # Jeune sain\n",
    "\n",
    "# Sauvegarde du nouveau jeu de données avec les poids\n",
    "data_c.to_csv(\"HERRERA_NATIVI_VLADIMIR/metadata_c_with_weights.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform-Sampling reweighting\n",
    "\n",
    "Maintenant on s'intéresse a un deuxième algorithme du cours: Uniform sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Favorisés : Jeunes (0-20 ans), Femmes (F), PA\n",
    "\n",
    "# Défavorisés : Adultes (41-80 ans), Hommes (M), AP\n",
    "\n",
    "def uniform_sampling(D, S, Label):\n",
    "    W = []\n",
    "    groupes = groupes_bw(S)\n",
    "    for s in groupes:\n",
    "        for c in [0, 1]:\n",
    "            num = ((D[S] == s).sum())*((D[Label]==c).sum())\n",
    "            denom = (((D[S] == s) & (D[Label] == c)).sum()) * D.shape[0]\n",
    "            poid = num / denom\n",
    "            W.append(poid)\n",
    "\n",
    "    nb_DN = ((D[S] == groupes[0]) & (D[Label] == 0)).sum()\n",
    "    nb_DP = ((D[S] == groupes[0]) & (D[Label] == 1)).sum()\n",
    "    nb_FN = ((D[S] == groupes[1]) & (D[Label] == 0)).sum()\n",
    "    nb_FP = ((D[S] == groupes[1]) & (D[Label] == 1)).sum()\n",
    "\n",
    "    nb_samples_DN = int(W[0]*nb_DN)\n",
    "    nb_samples_DP = int(W[1]*nb_DP)\n",
    "    nb_samples_FN = int(W[2]*nb_FN)\n",
    "    nb_samples_FP = int(W[3]*nb_FP)\n",
    "\n",
    "    samples_DN = D[(D[S] == groupes[0]) & (D[Label] == 0)].sample(n=nb_samples_DN, replace=True)  \n",
    "    samples_DP = D[(D[S] == groupes[0]) & (D[Label] == 1)].sample(n=nb_samples_DP, replace=True)\n",
    "    samples_FN = D[(D[S] == groupes[1]) & (D[Label] == 0)].sample(n=nb_samples_FN, replace=True)\n",
    "    samples_FP = D[(D[S] == groupes[1]) & (D[Label] == 1)].sample(n=nb_samples_FP, replace=True)\n",
    "    \n",
    "    df_resampled = pd.concat([samples_DN, samples_DP, samples_FN, samples_FP])\n",
    "\n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a constaté que l'attribut \"View Position\" ne peut pas être un biais car ça n'as pas de sense de discriminer quelqu'un par la \"View Position\".\n",
    "\n",
    "Ici, on affecte \"df_sexe\" et \"df_age\" avec Uniform Sampling, et on sauvegarde le dataframe pour l'entreiner plus tard dans le fichier \"train_classifieur.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Favorisés : Jeunes (0-20 ans), Femmes (F), PA\n",
    "# Défavorisés : Adultes (41-80 ans), Hommes (M), AP\n",
    "\n",
    "df_sexe = uniform_sampling(data, \"Patient Gender\", \"Finding Labels\")\n",
    "df_age = uniform_sampling(data, \"Patient Gender\", \"Finding Labels\")\n",
    "\n",
    "\n",
    "df_sexe.to_csv(\"HERRERA_NATIVI_VLADIMIR/metadata_uniform_genre.csv\", index=False)\n",
    "df_age.to_csv(\"HERRERA_NATIVI_VLADIMIR/metadata_uniform_age.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIF360\n",
    "\n",
    "On veut maintenant appliquer les méthodes de fairness en utilisant directement la bibliothèque AIF360.\n",
    "\n",
    "Dans un premier temps, on fait une table de correspondance pour pouvoir recupérer les \"Image Index\", pour pouvoir bien entraîner nas modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation du type de la colonne Image Index (string) en int et création de la table de correspondance \n",
    "\n",
    "mapping_dict = {val: idx for idx, val in enumerate(data['Image Index'].unique())}\n",
    "data['Image Index'] = data['Image Index'].map(mapping_dict)\n",
    "mapping_table = pd.DataFrame(list(mapping_dict.items()), columns=['Ancien Image Index', 'Nouveau Index'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on diviser notre dataframe en 2: Validation et Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data[\"train\"] == True].copy()\n",
    "data_val = data[data[\"train\"] == False].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creer une instance de StandardDataset de AIF360\n",
    "\n",
    "On encode nos données au cas où il ne sont pas encore encodés pour pouvoir ensuite transformer notre dataframe en DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dictionnaire pour gérer les colonnes catégorielles encodées en one-hot\n",
    "# Ce dictionnaire va associer chaque nom de colonne catégorielle originale\n",
    "# à la liste des colonnes one-hot correspondantes dans le DataFrame\n",
    "\n",
    "categorical_columns_dic = {}\n",
    "for col in data.columns:\n",
    "    col_split = col.split(\"=\")\n",
    "    if len(col_split) > 1:\n",
    "        cat_col = col_split[0]\n",
    "        if not (cat_col in categorical_columns_dic.keys()):\n",
    "            categorical_columns_dic[cat_col] = []\n",
    "        categorical_columns_dic[cat_col].append(col)\n",
    "categorical_features = categorical_columns_dic.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des dataFrames en Dataset\n",
    "\n",
    "Comme dans les TDs, on trans les dataFrames de train, valid et général en Dataset, prennant en considération les attributs sur lesquels on va travailler, le label utilisé, la classe favorable et les classes privilégiés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDataset_train = StandardDataset(\n",
    "    df=data_train,\n",
    "    label_name=\"Finding Labels\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"Patient Gender\", \"Age Group\"],\n",
    "    privileged_classes=[[1],[0]], # a analyser \n",
    "    categorical_features=categorical_features,\n",
    "    na_values=[\"?\", \"Unknown/Invalid\"],\n",
    "    custom_preprocessing=None,\n",
    "    metadata=None,\n",
    ")\n",
    "\n",
    "MyDataset_val = StandardDataset(\n",
    "    df=data_val,\n",
    "    label_name=\"Finding Labels\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"Patient Gender\",\"Age Group\"],\n",
    "    privileged_classes=[[1],[0]], # a analyser \n",
    "    categorical_features=categorical_features,\n",
    "    na_values=[\"?\", \"Unknown/Invalid\"],\n",
    "    custom_preprocessing=None,\n",
    "    metadata=None,\n",
    ")\n",
    "\n",
    "MyDataset = StandardDataset(\n",
    "    df=data,\n",
    "    label_name=\"Finding Labels\",\n",
    "    favorable_classes=[1],\n",
    "    protected_attribute_names=[\"Patient Gender\",\"Age Group\"],\n",
    "    privileged_classes=[[1],[0]], # a analyser \n",
    "    categorical_features=categorical_features,\n",
    "    na_values=[\"?\", \"Unknown/Invalid\"],\n",
    "    custom_preprocessing=None,\n",
    "    metadata=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing : Implémentations Reweighing AIF360\n",
    "\n",
    "Dans cette partie, on a constaté que le Reweighing AIF360 effectué le même calcul qu'on a fait au début du pre-processing. \n",
    "Cependant, pour la méthode avec AIF360, on a séparé l'entrainement et la validation, et c'est pour cela qu'on a des poids diférents qu'au début."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Patient Gender',\n",
       " [{'Patient Gender': np.float64(0.0)}],\n",
       " [{'Patient Gender': np.float64(1.0)}])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_ind = 0\n",
    "sens_attr = MyDataset_train.protected_attribute_names[sens_ind]\n",
    "unprivileged_groups = [\n",
    "    {sens_attr: v}\n",
    "    for v in MyDataset_train.unprivileged_protected_attributes[sens_ind]\n",
    "]\n",
    "privileged_groups = [\n",
    "    {sens_attr: v}\n",
    "    for v in MyDataset_train.privileged_protected_attributes[sens_ind]\n",
    "]\n",
    "sens_attr, unprivileged_groups, privileged_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing sur le genre\n",
    "\n",
    "Pour les deux cas de Reweighing, on affecte les trois variables dataset_transf_train, dataset_transf_val et dataset_transf, après avoir entrainé notre model. \n",
    "\"dataset_transf\" va nous permettre d'alloué les nouveaux poids calculés pour l'entrainement sans probèmes de taille dans notre fichier csv avec le reste des poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW_gender = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups\n",
    ")\n",
    "\n",
    "RW_gender.fit(MyDataset_train)\n",
    "\n",
    "dataset_transf = RW_gender.transform(MyDataset)\n",
    "\n",
    "dataset_transf_train = RW_gender.transform(MyDataset_train)\n",
    "dataset_transf_val = RW_gender.transform(MyDataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reweighing sur l'âge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Age Group',\n",
       " [{'Age Group': np.float64(1.0)}],\n",
       " [{'Age Group': np.float64(0.0)}])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens_ind_age = 1\n",
    "sens_attr_age = MyDataset_train.protected_attribute_names[sens_ind_age]\n",
    "unprivileged_groups_age = [\n",
    "    {sens_attr_age: v}\n",
    "    for v in MyDataset_train.unprivileged_protected_attributes[sens_ind_age]\n",
    "]\n",
    "privileged_groups_age = [\n",
    "    {sens_attr_age: v}\n",
    "    for v in MyDataset_train.privileged_protected_attributes[sens_ind_age]\n",
    "]\n",
    "sens_attr_age, unprivileged_groups_age, privileged_groups_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW_age = Reweighing(\n",
    "    unprivileged_groups=unprivileged_groups_age, privileged_groups=privileged_groups_age\n",
    ")\n",
    "\n",
    "RW_age.fit(MyDataset_train)\n",
    "\n",
    "dataset_transf_age = RW_age.transform(MyDataset)\n",
    "\n",
    "dataset_transf_age_train = RW_age.transform(MyDataset_train)\n",
    "dataset_trans_age_val = RW_age.transform(MyDataset_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On introduit deux colonnes avec les poids calculés a notre dataframe non encodé, de manière \"automatique\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>WEIGHTS</th>\n",
       "      <th>train</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>poids_reweigth_gender</th>\n",
       "      <th>poids_reweigth_PA</th>\n",
       "      <th>poids_reweigth_age</th>\n",
       "      <th>weights_gender_aif360</th>\n",
       "      <th>weights_age_aif360</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000006_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.021751</td>\n",
       "      <td>0.919727</td>\n",
       "      <td>1.012577</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.997075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000025_000.png</td>\n",
       "      <td>Effusion</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>71</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>1.114974</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>1.008043</td>\n",
       "      <td>1.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000029_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973446</td>\n",
       "      <td>0.919727</td>\n",
       "      <td>1.012577</td>\n",
       "      <td>1.007274</td>\n",
       "      <td>0.997075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000072_000.png</td>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.033302</td>\n",
       "      <td>1.114974</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>0.990955</td>\n",
       "      <td>1.003722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000090_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>67</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973446</td>\n",
       "      <td>0.919727</td>\n",
       "      <td>1.012577</td>\n",
       "      <td>1.007274</td>\n",
       "      <td>0.997075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>00030752_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30752</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973446</td>\n",
       "      <td>1.150693</td>\n",
       "      <td>1.012577</td>\n",
       "      <td>1.007274</td>\n",
       "      <td>0.997075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>00030772_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30772</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973446</td>\n",
       "      <td>1.150693</td>\n",
       "      <td>0.974216</td>\n",
       "      <td>1.007274</td>\n",
       "      <td>1.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>00030772_001.png</td>\n",
       "      <td>Consolidation</td>\n",
       "      <td>1</td>\n",
       "      <td>30772</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.033302</td>\n",
       "      <td>0.866009</td>\n",
       "      <td>1.032278</td>\n",
       "      <td>0.990955</td>\n",
       "      <td>0.993207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>00030772_002.png</td>\n",
       "      <td>Consolidation</td>\n",
       "      <td>2</td>\n",
       "      <td>30772</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.033302</td>\n",
       "      <td>0.866009</td>\n",
       "      <td>1.032278</td>\n",
       "      <td>0.990955</td>\n",
       "      <td>0.993207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>00030805_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>30805</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.021751</td>\n",
       "      <td>0.919727</td>\n",
       "      <td>0.974216</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>1.005441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5626 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
       "0     00000006_000.png     No Finding            0           6           81   \n",
       "1     00000025_000.png       Effusion            0          25           71   \n",
       "2     00000029_000.png     No Finding            0          29           59   \n",
       "3     00000072_000.png    Atelectasis            0          72           67   \n",
       "4     00000090_000.png     No Finding            0          90           67   \n",
       "...                ...            ...          ...         ...          ...   \n",
       "5622  00030752_000.png     No Finding            0       30752           64   \n",
       "5623  00030772_000.png     No Finding            0       30772           26   \n",
       "5624  00030772_001.png  Consolidation            1       30772           26   \n",
       "5625  00030772_002.png  Consolidation            2       30772           26   \n",
       "5626  00030805_000.png     No Finding            0       30805           27   \n",
       "\n",
       "     Patient Gender View Position  WEIGHTS  train  Age Group  \\\n",
       "0                 M            PA        1   True          1   \n",
       "1                 M            PA        1   True          1   \n",
       "2                 F            PA        1  False          1   \n",
       "3                 F            PA        1   True          1   \n",
       "4                 F            PA        1   True          1   \n",
       "...             ...           ...      ...    ...        ...   \n",
       "5622              F            AP        1   True          1   \n",
       "5623              F            AP        1   True          0   \n",
       "5624              F            AP        1   True          0   \n",
       "5625              F            AP        1   True          0   \n",
       "5626              M            PA        1   True          0   \n",
       "\n",
       "      poids_reweigth_gender  poids_reweigth_PA  poids_reweigth_age  \\\n",
       "0                  1.021751           0.919727            1.012577   \n",
       "1                  0.975466           1.114974            0.985537   \n",
       "2                  0.973446           0.919727            1.012577   \n",
       "3                  1.033302           1.114974            0.985537   \n",
       "4                  0.973446           0.919727            1.012577   \n",
       "...                     ...                ...                 ...   \n",
       "5622               0.973446           1.150693            1.012577   \n",
       "5623               0.973446           1.150693            0.974216   \n",
       "5624               1.033302           0.866009            1.032278   \n",
       "5625               1.033302           0.866009            1.032278   \n",
       "5626               1.021751           0.919727            0.974216   \n",
       "\n",
       "      weights_gender_aif360  weights_age_aif360  \n",
       "0                  0.993727            0.997075  \n",
       "1                  1.008043            1.003722  \n",
       "2                  1.007274            0.997075  \n",
       "3                  0.990955            1.003722  \n",
       "4                  1.007274            0.997075  \n",
       "...                     ...                 ...  \n",
       "5622               1.007274            0.997075  \n",
       "5623               1.007274            1.005441  \n",
       "5624               0.990955            0.993207  \n",
       "5625               0.990955            0.993207  \n",
       "5626               0.993727            1.005441  \n",
       "\n",
       "[5626 rows x 15 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajout des weights calculés avec aif360\n",
    "data_c[\"weights_gender_aif360\"] = dataset_transf.instance_weights\n",
    "data_c[\"weights_age_aif360\"] = dataset_transf_age.instance_weights\n",
    "# Sauvegarder data_c mit à jour avec les nouvelles colonnes\n",
    "data_c.to_csv(\"HERRERA_NATIVI_VLADIMIR/metadata_c_with_weights.csv\", index=False)\n",
    "data_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disparate Impact Remover \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights    features                         \\\n",
       "                                                                     \n",
       "                                Image Index Follow-up # Patient ID   \n",
       "instance names                                                       \n",
       "0                           1.0         0.0         0.0        6.0   \n",
       "1                           1.0         1.0         0.0       25.0   \n",
       "3                           1.0         0.0         0.0        6.0   \n",
       "4                           1.0         1.0         0.0       25.0   \n",
       "5                           1.0         5.0         0.0       25.0   \n",
       "...                         ...         ...         ...        ...   \n",
       "5622                        1.0      5615.0         0.0    30711.0   \n",
       "5623                        1.0      5618.0         0.0    30772.0   \n",
       "5624                        1.0      5619.0         0.0    30772.0   \n",
       "5625                        1.0      5624.0         1.0    30772.0   \n",
       "5626                        1.0      5624.0         0.0    30772.0   \n",
       "\n",
       "                                                                            \\\n",
       "                           protected attribute                               \n",
       "               Patient Age      Patient Gender View Position WEIGHTS train   \n",
       "instance names                                                               \n",
       "0                     77.0                 0.0           0.0     1.0   1.0   \n",
       "1                     67.0                 0.0           0.0     1.0   1.0   \n",
       "3                     67.0                 1.0           0.0     1.0   1.0   \n",
       "4                     67.0                 1.0           0.0     1.0   1.0   \n",
       "5                     68.0                 1.0           1.0     1.0   1.0   \n",
       "...                    ...                 ...           ...     ...   ...   \n",
       "5622                  64.0                 1.0           1.0     1.0   1.0   \n",
       "5623                  26.0                 1.0           1.0     1.0   1.0   \n",
       "5624                  26.0                 1.0           1.0     1.0   1.0   \n",
       "5625                  26.0                 1.0           1.0     1.0   1.0   \n",
       "5626                  26.0                 0.0           0.0     1.0   1.0   \n",
       "\n",
       "                                   labels  \n",
       "               protected attribute         \n",
       "                         Age Group         \n",
       "instance names                             \n",
       "0                              1.0    1.0  \n",
       "1                              1.0    0.0  \n",
       "3                              1.0    0.0  \n",
       "4                              1.0    1.0  \n",
       "5                              1.0    1.0  \n",
       "...                            ...    ...  \n",
       "5622                           1.0    1.0  \n",
       "5623                           0.0    1.0  \n",
       "5624                           0.0    0.0  \n",
       "5625                           0.0    0.0  \n",
       "5626                           0.0    1.0  \n",
       "\n",
       "[4170 rows x 11 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disparate Impact Remover : PATIENT GENDER \n",
    "\n",
    "DIR_gender = DisparateImpactRemover(repair_level=1.0, sensitive_attribute=\"Patient Gender\")\n",
    "\n",
    "DIR_gender.fit(MyDataset_train)\n",
    "\n",
    "dataset_transf_dir_gender = DIR_gender.fit_transform(MyDataset)\n",
    "dataset_transf_dir_gender_train = DIR_gender.fit_transform(MyDataset_train)\n",
    "dataset_transf_dir_gender_val = DIR_gender.fit_transform(MyDataset_val)\n",
    "\n",
    "dataset_transf_dir_gender_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights    features                         \\\n",
       "                                                                     \n",
       "                                Image Index Follow-up # Patient ID   \n",
       "instance names                                                       \n",
       "0                           1.0         0.0         0.0        6.0   \n",
       "1                           1.0         0.0         0.0        6.0   \n",
       "3                           1.0         3.0         0.0       72.0   \n",
       "4                           1.0         3.0         0.0       72.0   \n",
       "5                           1.0         5.0         1.0       72.0   \n",
       "...                         ...         ...         ...        ...   \n",
       "5622                        1.0      5619.0         0.0    30711.0   \n",
       "5623                        1.0      5612.0         0.0    30687.0   \n",
       "5624                        1.0      5613.0         1.0    30687.0   \n",
       "5625                        1.0      5617.0         2.0    30687.0   \n",
       "5626                        1.0      5619.0         0.0    30711.0   \n",
       "\n",
       "                                                                            \\\n",
       "                           protected attribute                               \n",
       "               Patient Age      Patient Gender View Position WEIGHTS train   \n",
       "instance names                                                               \n",
       "0                     32.0                 0.0           0.0     1.0   1.0   \n",
       "1                     25.0                 0.0           0.0     1.0   1.0   \n",
       "3                     22.0                 1.0           0.0     1.0   1.0   \n",
       "4                     22.0                 1.0           0.0     1.0   1.0   \n",
       "5                     22.0                 1.0           1.0     1.0   1.0   \n",
       "...                    ...                 ...           ...     ...   ...   \n",
       "5622                  19.0                 1.0           1.0     1.0   1.0   \n",
       "5623                  26.0                 1.0           1.0     1.0   1.0   \n",
       "5624                  26.0                 1.0           1.0     1.0   1.0   \n",
       "5625                  26.0                 1.0           1.0     1.0   1.0   \n",
       "5626                  27.0                 0.0           0.0     1.0   1.0   \n",
       "\n",
       "                                   labels  \n",
       "               protected attribute         \n",
       "                         Age Group         \n",
       "instance names                             \n",
       "0                              1.0    1.0  \n",
       "1                              1.0    0.0  \n",
       "3                              1.0    0.0  \n",
       "4                              1.0    1.0  \n",
       "5                              1.0    1.0  \n",
       "...                            ...    ...  \n",
       "5622                           1.0    1.0  \n",
       "5623                           0.0    1.0  \n",
       "5624                           0.0    0.0  \n",
       "5625                           0.0    0.0  \n",
       "5626                           0.0    1.0  \n",
       "\n",
       "[4170 rows x 11 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disparate Impact Remover : AGE GROUP\n",
    "\n",
    "DIR_age = DisparateImpactRemover(repair_level=1.0, sensitive_attribute=\"Age Group\")\n",
    "DIR_age.fit(MyDataset_train)\n",
    "\n",
    "dataset_transf_dir_age = DIR_age.fit_transform(MyDataset)\n",
    "dataset_transf_dir_age_train = DIR_age.fit_transform(MyDataset_train)\n",
    "dataset_transf_dir_age_val = DIR_age.fit_transform(MyDataset_val)\n",
    "\n",
    "dataset_transf_dir_age_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>WEIGHTS</th>\n",
       "      <th>train</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Finding Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>5619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30711.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>5610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30687.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>5613.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30687.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>5617.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30687.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>5619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30711.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5626 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Index  Follow-up #  Patient ID  Patient Age  Patient Gender  \\\n",
       "0             0.0          0.0         6.0         32.0             0.0   \n",
       "1             0.0          0.0         6.0         25.0             0.0   \n",
       "2             2.0          0.0        29.0         16.0             1.0   \n",
       "3             2.0          0.0        29.0         22.0             1.0   \n",
       "4             4.0          0.0        90.0         22.0             1.0   \n",
       "...           ...          ...         ...          ...             ...   \n",
       "5622       5619.0          0.0     30711.0         19.0             1.0   \n",
       "5623       5610.0          0.0     30687.0         26.0             1.0   \n",
       "5624       5613.0          1.0     30687.0         26.0             1.0   \n",
       "5625       5617.0          2.0     30687.0         26.0             1.0   \n",
       "5626       5619.0          0.0     30711.0         27.0             0.0   \n",
       "\n",
       "      View Position  WEIGHTS  train  Age Group  Finding Labels  \n",
       "0               0.0      1.0    1.0        1.0             1.0  \n",
       "1               0.0      1.0    1.0        1.0             0.0  \n",
       "2               0.0      1.0    0.0        1.0             1.0  \n",
       "3               0.0      1.0    1.0        1.0             0.0  \n",
       "4               0.0      1.0    1.0        1.0             1.0  \n",
       "...             ...      ...    ...        ...             ...  \n",
       "5622            1.0      1.0    1.0        1.0             1.0  \n",
       "5623            1.0      1.0    1.0        0.0             1.0  \n",
       "5624            1.0      1.0    1.0        0.0             0.0  \n",
       "5625            1.0      1.0    1.0        0.0             0.0  \n",
       "5626            0.0      1.0    1.0        0.0             1.0  \n",
       "\n",
       "[5626 rows x 10 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed_gender = dataset_transf_dir_gender.convert_to_dataframe()[0]\n",
    "data_transformed_age = dataset_transf_dir_age.convert_to_dataframe()[0]\n",
    "\n",
    "\n",
    "# Ajouter les données transformées au DataFrame existant\n",
    "# Vous pouvez ajouter les colonnes nécessaires de `data_transformed_gender` au DataFrame `data_dir_gender`\n",
    "data_dir_gender = data_transformed_gender.copy()\n",
    "data_dir_age = data_transformed_age.copy()\n",
    "\n",
    "data_dir_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire inverse où les clés sont les nouveaux index et les valeurs sont les anciens noms\n",
    "inverse_mapping = {v: k for k, v in mapping_dict.items()}\n",
    "\n",
    "# Appliquer ce mapping inverse à data_dir_gender et à data_dir_age pour retrouver les noms originaux\n",
    "data_dir_gender['Image Index'] = data_dir_gender['Image Index'].map(inverse_mapping)\n",
    "data_dir_age['Image Index'] = data_dir_age['Image Index'].map(inverse_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_gender.to_csv(\"HERRERA_NATIVI_VLADIMIR/metadata_DIR_genre.csv\", index=False)\n",
    "data_dir_age.to_csv(\"HERRERA_NATIVI_VLADIMIR/metadata_DIR_age.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cacul de metriques suite au pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_metrics(\n",
    "    y_true,\n",
    "    y_pred=None,\n",
    "    prot_attr=None,\n",
    "    priv_group=1,\n",
    "    pos_label=1,\n",
    "    sample_weight=None,\n",
    "):\n",
    "    group_metrics = {}\n",
    "    group_metrics[\"base_rate\"] = base_rate(\n",
    "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    if not y_pred is None:\n",
    "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "    return group_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métriques originales: {'base_rate': np.float64(0.5415926057589762), 'statistical_parity_difference': np.float64(0.5416888888888889), 'disparate_impact_ratio': 0.0} \n",
      "\n",
      "Métriques après Reweighing (Gender): {'base_rate': np.float64(0.5413524681936874), 'statistical_parity_difference': np.float64(-0.03389554132548789), 'disparate_impact_ratio': 0.9395148406767924}\n",
      "Métriques après Reweighing (Age): {'base_rate': np.float64(0.541431091861975), 'statistical_parity_difference': np.float64(-0.02573446024774384), 'disparate_impact_ratio': 0.9539589999836494}\n",
      "Métriques après Disparate Impact Remover (Gender): {'base_rate': np.float64(0.5415926057589762), 'statistical_parity_difference': np.float64(-0.02630329442442525), 'disparate_impact_ratio': 0.9527230874266526}\n",
      "Métriques après Disparate Impact Remover (Age): {'base_rate': np.float64(0.5415926057589762), 'statistical_parity_difference': np.float64(-0.02106104410981824), 'disparate_impact_ratio': 0.9621154191538104}\n",
      "Métriques après Uniform Sampling (Gender): {'base_rate': np.float64(0.5416073968705548), 'statistical_parity_difference': np.float64(4.494708123292668e-05), 'disparate_impact_ratio': 1.000082992176209}\n",
      "Métriques après Uniform Sampling  (Age): {'base_rate': np.float64(0.5416073968705548), 'statistical_parity_difference': np.float64(-0.028909529371586196), 'disparate_impact_ratio': 0.9485350148999575}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Ratio is ill-defined and being set to 0.0 due to no positive privileged samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_orig = get_group_metrics(\n",
    "    y_true=data[\"Finding Labels\"],  # Utilisez .labels pour accéder aux étiquettes\n",
    "    priv_group=1,\n",
    "    pos_label=1,  \n",
    "    sample_weight = data_c.WEIGHTS\n",
    ")\n",
    "\n",
    "# Pour les données transformées par Reweighing pour le sexe\n",
    "metrics_rw_gender = get_group_metrics(\n",
    "    y_true=data[\"Finding Labels\"],  # Utilisez .labels pour accéder aux étiquettes\n",
    "    prot_attr=data[\"Patient Gender\"],  # L'attribut protégé (ici \"Patient Gender\")\n",
    "    priv_group=1,\n",
    "    pos_label=1,  \n",
    "    sample_weight = data_c.weights_gender_aif360\n",
    ")\n",
    "\n",
    "# Pour les données transformées par Reweighing pour l'âge\n",
    "metrics_rw_age = get_group_metrics(\n",
    "    y_true=data[\"Finding Labels\"],  \n",
    "    prot_attr=data[\"Age Group\"], \n",
    "    priv_group=0,\n",
    "    pos_label=1,\n",
    "    sample_weight=data_c.weights_age_aif360\n",
    ")\n",
    "\n",
    "# Pour les données transformées par DisparateImpactRemover pour le sexe\n",
    "metrics_dir_gender = get_group_metrics(\n",
    "    y_true=data_dir_gender[\"Finding Labels\"],  \n",
    "    prot_attr=data_dir_gender[\"Patient Gender\"], \n",
    "    priv_group=1,\n",
    "    pos_label=1,\n",
    "    sample_weight=data_dir_gender.WEIGHTS\n",
    ")\n",
    "\n",
    "# Pour les données transformées par DisparateImpactRemover pour l'âge\n",
    "metrics_dir_age = get_group_metrics(\n",
    "    y_true=data_dir_gender[\"Finding Labels\"],  \n",
    "    prot_attr=data_dir_age[\"Age Group\"], \n",
    "    priv_group=0,\n",
    "    pos_label=1,\n",
    "    sample_weight=data_dir_age.WEIGHTS\n",
    ")\n",
    "\n",
    "# Pour les données transformées par DisparateImpactRemover pour le sexe\n",
    "metrics_uniform_gender = get_group_metrics(\n",
    "    y_true=df_sexe[\"Finding Labels\"],  \n",
    "    prot_attr=df_sexe[\"Patient Gender\"], \n",
    "    priv_group=1,\n",
    "    pos_label=1,\n",
    "    sample_weight=df_sexe.WEIGHTS\n",
    ")\n",
    "\n",
    "# Pour les données transformées par DisparateImpactRemover pour l'âge\n",
    "metrics_uniform_age = get_group_metrics(\n",
    "    y_true=df_age[\"Finding Labels\"],  \n",
    "    prot_attr=df_age[\"Age Group\"], \n",
    "    priv_group=0,\n",
    "    pos_label=1,\n",
    "    sample_weight=df_age.WEIGHTS\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Afficher ou analyser les résultats\n",
    "print(\"Métriques originales:\", metrics_orig , \"\\n\")\n",
    "print(\"Métriques après Reweighing (Gender):\", metrics_rw_gender, \"\\n\")\n",
    "print(\"Métriques après Reweighing (Age):\", metrics_rw_age, \"\\n\")\n",
    "print(\"Métriques après Disparate Impact Remover (Gender):\", metrics_dir_gender, \"\\n\")\n",
    "print(\"Métriques après Disparate Impact Remover (Age):\", metrics_dir_age, \"\\n\")\n",
    "print(\"Métriques après Uniform Sampling (Gender):\", metrics_uniform_gender, \"\\n\")\n",
    "print(\"Métriques après Uniform Sampling  (Age):\", metrics_uniform_age, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On effectuera une regression logistique qui nos permettra d'obtenir les probabiltés de predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reject-option classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Analyzing attribute: Patient Gender\n",
      "========================================\n",
      "\n",
      "Patient Gender fairness metrics:\n",
      "  Optimal threshold: 0.4900\n",
      "  Statistical parity difference: 0.0288\n",
      "  Equal opportunity difference: 0.0466\n",
      "  Average odds difference: 0.0454\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Age Group\n",
      "========================================\n",
      "\n",
      "Age Group fairness metrics:\n",
      "  Optimal threshold: 0.4900\n",
      "  Statistical parity difference: 0.0135\n",
      "  Equal opportunity difference: 0.0440\n",
      "  Average odds difference: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/aif360/algorithms/postprocessing/reject_option_classification.py:160: UserWarning:\n",
      "\n",
      "Unable to satisy fairness constraints\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final combined metrics:\n",
      "Statistical parity difference: -0.1098\n",
      "Equal opportunity difference: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "from aif360.metrics import ClassificationMetric\n",
    "import pandas as pd\n",
    "\n",
    "def single_attribute_fairness_analysis(dataset_train, dataset_val, protected_attributes):\n",
    "    \"\"\"\n",
    "    Perform ROC fairness adjustment for each protected attribute separately\n",
    "    \n",
    "    Args:\n",
    "        dataset_train: AIF360 training dataset\n",
    "        dataset_val: AIF360 validation dataset\n",
    "        protected_attributes: List of protected attribute names to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of fairness metrics per attribute\n",
    "    \"\"\"\n",
    "    # 1. Train base model\n",
    "    model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "    model.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    \n",
    "    # 2. Get predicted scores\n",
    "    val_scores = model.predict_proba(dataset_val.features)[:, 1]\n",
    "    val_pred = dataset_val.copy(deepcopy=True)\n",
    "    val_pred.scores = val_scores.reshape(-1, 1)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for attr in protected_attributes:\n",
    "        print(f\"\\n{'='*40}\\nAnalyzing attribute: {attr}\\n{'='*40}\")\n",
    "        \n",
    "        # 3. Get attribute-specific groups\n",
    "        attr_idx = dataset_val.protected_attribute_names.index(attr)\n",
    "        privileged_group = [{attr: dataset_val.privileged_protected_attributes[attr_idx][0]}]\n",
    "        unprivileged_group = [{attr: v} for v in dataset_val.unprivileged_protected_attributes[attr_idx]]\n",
    "        \n",
    "        # 4. Configure ROC\n",
    "        roc = RejectOptionClassification(\n",
    "            unprivileged_groups=unprivileged_group,\n",
    "            privileged_groups=privileged_group,\n",
    "            metric_name=\"Statistical parity difference\",\n",
    "            metric_ub=0.05,\n",
    "            metric_lb=-0.05,\n",
    "            low_class_thresh=0.01,\n",
    "            high_class_thresh=0.99,\n",
    "            num_class_thresh=50,\n",
    "            num_ROC_margin=30,\n",
    "        )\n",
    "        \n",
    "        # 5. Fit and predict\n",
    "        roc.fit(dataset_val, val_pred)\n",
    "        fair_pred = roc.predict(val_pred)\n",
    "        \n",
    "        # 6. Calculate metrics\n",
    "        metric = ClassificationMetric(\n",
    "            dataset_val,\n",
    "            fair_pred,\n",
    "            unprivileged_groups=unprivileged_group,\n",
    "            privileged_groups=privileged_group\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[attr] = {\n",
    "            'threshold': roc.classification_threshold,\n",
    "            'margin': roc.ROC_margin,\n",
    "            'spd': metric.statistical_parity_difference(),\n",
    "            'eod': metric.equal_opportunity_difference(),\n",
    "            'aod': metric.average_odds_difference()\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{attr} fairness metrics:\")\n",
    "        print(f\"  Optimal threshold: {results[attr]['threshold']:.4f}\")\n",
    "        print(f\"  Statistical parity difference: {results[attr]['spd']:.4f}\")\n",
    "        print(f\"  Equal opportunity difference: {results[attr]['eod']:.4f}\")\n",
    "        print(f\"  Average odds difference: {results[attr]['aod']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# =================================================================\n",
    "# Usage with your dataset\n",
    "# =================================================================\n",
    "\n",
    "# List of protected attributes to analyze separately\n",
    "protected_attributes = [\"Patient Gender\", \"Age Group\"]\n",
    "\n",
    "# Run analysis\n",
    "metrics_results = single_attribute_fairness_analysis(\n",
    "    MyDataset_train,\n",
    "    MyDataset_val,\n",
    "    protected_attributes\n",
    ")\n",
    "\n",
    "# Optional: Create combined fair predictions\n",
    "final_predictions = MyDataset_val.copy(deepcopy=True)\n",
    "for attr in protected_attributes:\n",
    "    # Get attribute-specific predictions\n",
    "    attr_idx = MyDataset_val.protected_attribute_names.index(attr)\n",
    "    privileged_group = [{attr: MyDataset_val.privileged_protected_attributes[attr_idx][0]}]\n",
    "    unprivileged_group = [{attr: v} for v in MyDataset_val.unprivileged_protected_attributes[attr_idx]]\n",
    "    \n",
    "    roc = RejectOptionClassification(\n",
    "        unprivileged_groups=unprivileged_group,\n",
    "        privileged_groups=privileged_group,\n",
    "        metric_name=\"Statistical parity difference\",\n",
    "        metric_ub=0.05,\n",
    "        metric_lb=-0.05\n",
    "    ).fit(MyDataset_val, final_predictions)\n",
    "    \n",
    "    final_predictions = roc.predict(final_predictions)\n",
    "\n",
    "print(\"\\nFinal combined metrics:\")\n",
    "combined_metric = ClassificationMetric(\n",
    "    MyDataset_val,\n",
    "    final_predictions,\n",
    "    unprivileged_groups=unprivileged_groups,\n",
    "    privileged_groups=privileged_groups\n",
    ")\n",
    "print(f\"Statistical parity difference: {combined_metric.statistical_parity_difference():.4f}\")\n",
    "print(f\"Equal opportunity difference: {combined_metric.equal_opportunity_difference():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated Equalized-Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################\n",
      "Running analysis with cost constraint: fnr\n",
      "########################################\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Patient Gender\n",
      "========================================\n",
      "\n",
      "Patient Gender fairness metrics:\n",
      "  Statistical parity difference: -0.1106\n",
      "  Equal opportunity difference: -0.1076\n",
      "  Average odds difference: -0.0947\n",
      "  FNR difference: 0.1076\n",
      "  FPR difference: -0.0817\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Age Group\n",
      "========================================\n",
      "\n",
      "Age Group fairness metrics:\n",
      "  Statistical parity difference: -0.2835\n",
      "  Equal opportunity difference: -0.2824\n",
      "  Average odds difference: -0.2715\n",
      "  FNR difference: 0.2824\n",
      "  FPR difference: -0.2606\n",
      "\n",
      "########################################\n",
      "Running analysis with cost constraint: fpr\n",
      "########################################\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Patient Gender\n",
      "========================================\n",
      "\n",
      "Patient Gender fairness metrics:\n",
      "  Statistical parity difference: -0.1125\n",
      "  Equal opportunity difference: -0.1110\n",
      "  Average odds difference: -0.0964\n",
      "  FNR difference: 0.1110\n",
      "  FPR difference: -0.0817\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Age Group\n",
      "========================================\n",
      "\n",
      "Age Group fairness metrics:\n",
      "  Statistical parity difference: -0.6586\n",
      "  Equal opportunity difference: -0.7243\n",
      "  Average odds difference: -0.6498\n",
      "  FNR difference: 0.7243\n",
      "  FPR difference: -0.5753\n",
      "\n",
      "########################################\n",
      "Running analysis with cost constraint: weighted\n",
      "########################################\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Patient Gender\n",
      "========================================\n",
      "\n",
      "Patient Gender fairness metrics:\n",
      "  Statistical parity difference: -0.2161\n",
      "  Equal opportunity difference: -0.1893\n",
      "  Average odds difference: -0.2038\n",
      "  FNR difference: 0.1893\n",
      "  FPR difference: -0.2183\n",
      "\n",
      "========================================\n",
      "Analyzing attribute: Age Group\n",
      "========================================\n",
      "\n",
      "Age Group fairness metrics:\n",
      "  Statistical parity difference: -0.4382\n",
      "  Equal opportunity difference: -0.4753\n",
      "  Average odds difference: -0.4280\n",
      "  FNR difference: 0.4753\n",
      "  FPR difference: -0.3808\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "\n",
    "def calibrated_eq_odds_analysis(dataset_train, dataset_val, protected_attributes, cost_constraint=\"fnr\"):\n",
    "    \"\"\"\n",
    "    Perform Calibrated Equalized Odds fairness adjustment for each protected attribute\n",
    "    \n",
    "    Args:\n",
    "        dataset_train: AIF360 training dataset\n",
    "        dataset_val: AIF360 validation dataset\n",
    "        protected_attributes: List of protected attribute names\n",
    "        cost_constraint: Optimization target (\"fnr\", \"fpr\", or \"weighted\")\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of fairness metrics per attribute\n",
    "    \"\"\"\n",
    "    # 1. Train base model\n",
    "    model = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42)\n",
    "    model.fit(dataset_train.features, dataset_train.labels.ravel())\n",
    "    \n",
    "    # 2. Get predicted scores\n",
    "    val_scores = model.predict_proba(dataset_val.features)[:, 1]\n",
    "    val_pred = dataset_val.copy(deepcopy=True)\n",
    "    val_pred.scores = val_scores.reshape(-1, 1)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for attr in protected_attributes:\n",
    "        print(f\"\\n{'='*40}\\nAnalyzing attribute: {attr}\\n{'='*40}\")\n",
    "        \n",
    "        # 3. Get attribute-specific groups\n",
    "        attr_idx = dataset_val.protected_attribute_names.index(attr)\n",
    "        privileged_group = [{attr: dataset_val.privileged_protected_attributes[attr_idx][0]}]\n",
    "        unprivileged_group = [{attr: v} for v in dataset_val.unprivileged_protected_attributes[attr_idx]]\n",
    "        \n",
    "        # 4. Configure Calibrated Equalized Odds\n",
    "        ceo = CalibratedEqOddsPostprocessing(\n",
    "            privileged_groups=privileged_group,\n",
    "            unprivileged_groups=unprivileged_group,\n",
    "            cost_constraint=cost_constraint,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        # 5. Fit and predict\n",
    "        ceo.fit(dataset_val, val_pred)\n",
    "        fair_pred = ceo.predict(val_pred)\n",
    "        \n",
    "        # 6. Calculate metrics\n",
    "        metric = ClassificationMetric(\n",
    "            dataset_val,\n",
    "            fair_pred,\n",
    "            unprivileged_groups=unprivileged_group,\n",
    "            privileged_groups=privileged_group\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        results[attr] = {\n",
    "            'spd': metric.statistical_parity_difference(),\n",
    "            'eod': metric.equal_opportunity_difference(),\n",
    "            'aod': metric.average_odds_difference(),\n",
    "            'fnr_diff': metric.false_negative_rate_difference(),\n",
    "            'fpr_diff': metric.false_positive_rate_difference()\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{attr} fairness metrics:\")\n",
    "        print(f\"  Statistical parity difference: {results[attr]['spd']:.4f}\")\n",
    "        print(f\"  Equal opportunity difference: {results[attr]['eod']:.4f}\")\n",
    "        print(f\"  Average odds difference: {results[attr]['aod']:.4f}\")\n",
    "        print(f\"  FNR difference: {results[attr]['fnr_diff']:.4f}\")\n",
    "        print(f\"  FPR difference: {results[attr]['fpr_diff']:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# =================================================================\n",
    "# Usage with your dataset\n",
    "# =================================================================\n",
    "\n",
    "# List of protected attributes\n",
    "protected_attributes = [\"Patient Gender\", \"Age Group\"]\n",
    "\n",
    "# Run analysis with different cost constraints\n",
    "for cost_constraint in [\"fnr\", \"fpr\", \"weighted\"]:\n",
    "    print(f\"\\n{'#'*40}\")\n",
    "    print(f\"Running analysis with cost constraint: {cost_constraint}\")\n",
    "    print(f\"{'#'*40}\")\n",
    "    \n",
    "    metrics_results = calibrated_eq_odds_analysis(\n",
    "        MyDataset_train,\n",
    "        MyDataset_val,\n",
    "        protected_attributes,\n",
    "        cost_constraint=cost_constraint\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de Metrics suite au Post-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'expe_log/predsOrig.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Predictions : \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preds_weights \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpe_log/predsOrig.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m preds_age_AIF360 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpe_log/predsAgeAIF360.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m preds_age_DIR \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpe_log/predsAgeDIR_AIF360.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Fairness/projet_fairness/projet_complet/.venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'expe_log/predsOrig.csv'"
     ]
    }
   ],
   "source": [
    "# Predictions : \n",
    "preds_weights = pd.read_csv(\"expe_log/predsOrig.csv\")\n",
    "preds_age_AIF360 = pd.read_csv(\"expe_log/predsAgeAIF360.csv\")\n",
    "preds_age_DIR = pd.read_csv(\"expe_log/predsAgeDIR_AIF360.csv\")\n",
    "preds_age_naive = pd.read_csv(\"expe_log/predsAgeNaive.csv\")\n",
    "preds_age_unifSampl = pd.read_csv(\"expe_log/predsAgeUniformSampling.csv\")\n",
    "preds_sexe_AIF360 = pd.read_csv(\"expe_log/predsGenderAIF360.csv\")\n",
    "preds_sexe_naive = pd.read_csv(\"expe_log/predsGenderNaive.csv\")\n",
    "preds_sexe_DIR = pd.read_csv(\"expe_log/predsGenreDIR_AIF360.csv\")\n",
    "preds_sexe_UnifSampl = pd.read_csv(\"expe_log/predsGenreUniformSampling.csv\")\n",
    "preds_pv_naive = pd.read_csv(\"expe_log/predsPANaive.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preds_weights['preds'] = (preds_weights['preds'] == 'sain').astype(int)\n",
    "preds_age_AIF360['preds'] = (preds_age_AIF360['preds'] == 'sain').astype(int)\n",
    "preds_age_DIR['preds'] = (preds_age_DIR['preds'] == 'sain').astype(int)\n",
    "preds_age_naive['preds'] = (preds_age_naive['preds'] == 'sain').astype(int)\n",
    "preds_age_unifSampl['preds'] = (preds_age_unifSampl['preds'] == 'sain').astype(int)\n",
    "preds_sexe_AIF360['preds'] = (preds_sexe_AIF360['preds'] == 'sain').astype(int)\n",
    "preds_sexe_naive['preds'] = (preds_sexe_naive['preds'] == 'sain').astype(int)\n",
    "preds_sexe_DIR['preds'] = (preds_sexe_DIR['preds'] == 'sain').astype(int)\n",
    "preds_sexe_UnifSampl['preds'] = (preds_sexe_UnifSampl['preds'] == 'sain').astype(int)\n",
    "preds_pv_naive['preds'] = (preds_pv_naive['preds'] == 'sain').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0393763368635225, np.float64(0.5415926057589762))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_files = {\n",
    "    \"Age AIF360\":             {\"file\": preds_age_AIF360, \"prot_attr\":                            data[\"Age Group\"],      \"sample_weight\": data_c.weights_age_aif360, \"class\": \"Age\"},\n",
    "    \"Ages DIR AIF360\":        {\"file\": preds_age_DIR, \"prot_attr\":       data_dir_age[\"Age Group\"],      \"sample_weight\": data_dir_age.WEIGHTS, \"class\": \"Age\"},\n",
    "    \"Age Naive\":              {\"file\": preds_age_naive, \"prot_attr\":             data[\"Age Group\"],      \"sample_weight\": data_c.poids_reweigth_age, \"class\": \"Age\"},\n",
    "    \"Age Uniform Sampling\":   {\"file\": preds_age_unifSampl, \"prot_attr\":   df_age[\"Age Group\"],      \"sample_weight\": df_age.WEIGHTS, \"class\": \"Age\", \"reshape\" : True, \"y_vrai\" : df_age[\"Finding Labels\"]},\n",
    "    \"Gender AIF360\":          {\"file\": preds_sexe_AIF360, \"prot_attr\":         data[\"Patient Gender\"], \"sample_weight\": data_c.weights_gender_aif360, \"class\": \"Sexe\"},\n",
    "    \"Genre Naive\":            {\"file\": preds_sexe_naive, \"prot_attr\":           data[\"Patient Gender\"], \"sample_weight\": data_c.poids_reweigth_gender, \"class\": \"Sexe\"},\n",
    "    \"Genre DIR AIF360\":       {\"file\": preds_sexe_DIR, \"prot_attr\":     data_dir_gender[\"Patient Gender\"], \"sample_weight\": data_dir_gender.WEIGHTS, \"class\": \"Sexe\"},\n",
    "    \"Genre Uniform Sampling\": {\"file\": preds_sexe_UnifSampl, \"prot_attr\": df_sexe[\"Patient Gender\"], \"sample_weight\": df_sexe.WEIGHTS, \"class\": \"Sexe\"},\n",
    "    \"Orig\":                   {\"file\": preds_weights, \"prot_attr\":                 data[\"Patient Gender\"], \"sample_weight\": data_c.WEIGHTS, \"class\": \"Sexe\"},\n",
    "    \"PANaive\":                {\"file\": preds_pv_naive, \"prot_attr\":              data[\"View Position\"], \"sample_weight\": data_c.poids_reweigth_PA, \"class\": \"VP\"}\n",
    "}\n",
    "\n",
    "all_metrics = {}\n",
    "\n",
    "for key, val in prediction_files.items():\n",
    "    preds_df = val[\"file\"]\n",
    "   \n",
    "\n",
    "    # Make sure the column with predictions is correctly referenced, e.g., \"Prediction\"\n",
    "    if val[\"class\"]==\"Age\": \n",
    "        if val[\"reshape\"]: \n",
    "            metrics = get_group_metrics(\n",
    "                y_true=val[\"y_vrai\"],\n",
    "                y_pred=preds_df[\"preds\"],\n",
    "                prot_attr=val[\"prot_attr\"],\n",
    "                priv_group=0,\n",
    "                pos_label=1,\n",
    "                sample_weight=val[\"sample_weight\"]\n",
    "            )\n",
    "        else : \n",
    "            metrics = get_group_metrics(\n",
    "                y_true=data[\"Finding Labels\"],\n",
    "                y_pred=preds_df[\"preds\"],\n",
    "                prot_attr=val[\"prot_attr\"],\n",
    "                priv_group=0,\n",
    "                pos_label=1,\n",
    "                sample_weight=val[\"sample_weight\"]\n",
    "            )\n",
    "        \n",
    "        all_metrics[key] = metrics\n",
    "    elif val[\"class\"]==\"Sexe\": \n",
    "        metrics = get_group_metrics(\n",
    "            y_true=data[\"Finding Labels\"],\n",
    "            y_pred=preds_df[\"preds\"],\n",
    "            prot_attr=val[\"prot_attr\"],\n",
    "            priv_group=1,\n",
    "            pos_label=1,\n",
    "            sample_weight=val[\"sample_weight\"]\n",
    "        )\n",
    "        \n",
    "        all_metrics[key] = metrics\n",
    "    elif val[\"class\"]==\"VP\": \n",
    "        metrics = get_group_metrics(\n",
    "            y_true=data[\"Finding Labels\"],\n",
    "            y_pred=preds_df[\"preds\"],\n",
    "            prot_attr=val[\"prot_attr\"],\n",
    "            priv_group=0,\n",
    "            pos_label=1,\n",
    "            sample_weight=val[\"sample_weight\"]\n",
    "        )\n",
    "        \n",
    "        all_metrics[key] = metrics\n",
    "\n",
    "\n",
    "for method, metrics in all_metrics.items():\n",
    "    print(f\"\\nMetrics for {method}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\" {metric_name} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
